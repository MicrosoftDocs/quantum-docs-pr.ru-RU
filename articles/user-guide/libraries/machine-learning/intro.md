---
title: Библиотека квантового машинного обучения
description: Узнайте, как машинное обучение используется в тактовых системах
author: alexeib2
ms.author: alexeib
ms.date: 11/22/2019
ms.topic: conceptual
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: e2f4a4a63eef40474856426b3b29652b5d3053b2
ms.sourcegitcommit: 71605ea9cc630e84e7ef29027e1f0ea06299747e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/26/2021
ms.locfileid: "98854036"
---
# <a name="introduction-to-quantum-machine-learning"></a><span data-ttu-id="1c675-103">Введение в тактовую Машинное обучение</span><span class="sxs-lookup"><span data-stu-id="1c675-103">Introduction to Quantum Machine Learning</span></span>

## <a name="framework-and-goals"></a><span data-ttu-id="1c675-104">Платформа и цели</span><span class="sxs-lookup"><span data-stu-id="1c675-104">Framework and goals</span></span>

<span data-ttu-id="1c675-105">Кодирование и обработка данных в такте — это мощная альтернатива классическим классификаторам тактов для машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="1c675-105">Quantum encoding and processing of information is a powerful alternative to classical machine learning Quantum classifiers.</span></span> <span data-ttu-id="1c675-106">В частности, это позволяет нам кодировать данные в тактовых регистрах, которые кратко относятся к числу функций, систематически применяя тактовый замкнутые в качестве вычислительного ресурса и применяют измерение тактов для вывода класса.</span><span class="sxs-lookup"><span data-stu-id="1c675-106">In particular, it allows us to encode data in quantum registers that are concise relative to the number of features, systematically employing quantum entanglement as computational resource and employing quantum measurement for class inference.</span></span>
<span data-ttu-id="1c675-107">Классификатор такта, ориентированный на канал, — это относительно простое решение, объединяющее кодировку данных с быстрой ентанглинг/распутывание запутанной сети тактовой цепью, за которым следует измерение для определения меток классов для выборок данных.</span><span class="sxs-lookup"><span data-stu-id="1c675-107">Circuit centric quantum classifier is a relatively simple quantum solution that combines data encoding with a rapidly entangling/disentangling quantum circuit followed by measurement to infer class labels of data samples.</span></span>
<span data-ttu-id="1c675-108">Цель состоит в том, чтобы обеспечить классический механизм распознавания и хранение цепей предметной области, а также гибридный такт или классический обучающий курс параметров канала даже для очень больших функциональных пространств.</span><span class="sxs-lookup"><span data-stu-id="1c675-108">The goal is to ensure classical characterization and storage of subject circuits, as well as hybrid quantum/classical training of the circuit parameters even for extremely large feature spaces.</span></span>

## <a name="classifier-architecture"></a><span data-ttu-id="1c675-109">Архитектура классификатора</span><span class="sxs-lookup"><span data-stu-id="1c675-109">Classifier architecture</span></span>

<span data-ttu-id="1c675-110">Классификация — это задача защищенного машинного обучения, где целью является определение меток классов $ \{ y_1, y_2, \лдотс, y_d \} $ некоторых примеров данных.</span><span class="sxs-lookup"><span data-stu-id="1c675-110">Classification is a supervised machine learning task, where the goal is to infer class labels $\{y_1,y_2,\ldots,y_d\}$ of certain data samples.</span></span> <span data-ttu-id="1c675-111">"Обучающий набор данных" — это коллекция примеров $ \Маскал{д} = \{ (x, y)} $ с известными предварительно назначенными метками.</span><span class="sxs-lookup"><span data-stu-id="1c675-111">The "training data set" is a collection of samples $\mathcal{D}=\{(x,y)}$ with known pre-assigned labels.</span></span> <span data-ttu-id="1c675-112">Здесь $x $ является образцом данных и $y $ — это известная метка с названием «обучающая метка».</span><span class="sxs-lookup"><span data-stu-id="1c675-112">Here $x$ is a data sample and $y$ is its known label called "training label".</span></span>
<span data-ttu-id="1c675-113">По аналогии с традиционными методами, классификация тактов состоит из трех этапов:</span><span class="sxs-lookup"><span data-stu-id="1c675-113">Somewhat similar to traditional methods, quantum classification consists of three steps:</span></span>
- <span data-ttu-id="1c675-114">кодирование данных</span><span class="sxs-lookup"><span data-stu-id="1c675-114">data encoding</span></span>
- <span data-ttu-id="1c675-115">подготовка состояния классификатора</span><span class="sxs-lookup"><span data-stu-id="1c675-115">preparation of a classifier state</span></span>
- <span data-ttu-id="1c675-116">измерения из-за природы вероятностная измерения, эти три шага должны повторяться несколько раз.</span><span class="sxs-lookup"><span data-stu-id="1c675-116">measurement Due to the probabilistic nature of the measurement, these three steps must be repeated multiple times.</span></span> <span data-ttu-id="1c675-117">Как кодирование, так и вычисления состояния классификатора выполняются с помощью *цепей тактов*.</span><span class="sxs-lookup"><span data-stu-id="1c675-117">Both the encoding and the computing of the classifier state are done by means of *quantum circuits*.</span></span> <span data-ttu-id="1c675-118">Несмотря на то, что канал кодирования обычно управляется данными и без параметров, цепь-классификатор содержит достаточный набор необходимых для изучения параметров.</span><span class="sxs-lookup"><span data-stu-id="1c675-118">While the encoding circuit is usually data-driven and parameter-free, the classifier circuit contains a sufficient set of learnable parameters.</span></span> 

<span data-ttu-id="1c675-119">В предложенном решении цепь-классификатор состоит из однокубитных поворотов и кубитных поворотов.</span><span class="sxs-lookup"><span data-stu-id="1c675-119">In the proposed solution the classifier circuit is composed of single-qubit rotations and two-qubit controlled rotations.</span></span> <span data-ttu-id="1c675-120">Для изучения этих параметров используются углы поворота.</span><span class="sxs-lookup"><span data-stu-id="1c675-120">The learnable parameters here are the rotation angles.</span></span> <span data-ttu-id="1c675-121">Шлюзы ротации и управления, управляемые, являются *универсальными* для вычислений тактов. Это означает, что любую одновесовую матрицу можно разложить на достаточно длинный канал, состоящий из таких шлюзов.</span><span class="sxs-lookup"><span data-stu-id="1c675-121">The rotation and controlled rotation gates are known to be *universal* for quantum computation, which means that any unitary weight matrix can be decomposed into a long enough circuit consisting of such gates.</span></span>

<span data-ttu-id="1c675-122">В предложенной версии поддерживается только один канал, за которым следует оценка с одной периодичностью.</span><span class="sxs-lookup"><span data-stu-id="1c675-122">In the proposed version, only one circuit followed by a single frequency estimation is supported.</span></span>
<span data-ttu-id="1c675-123">Таким же решением является тактовая аналогия аппаратного вектора поддержки с низким уровнем полинома.</span><span class="sxs-lookup"><span data-stu-id="1c675-123">Thus, the solution is a quantum analog of a support vector machine with a low-degree polynomial kernel.</span></span>

![Многоуровневый перцептрона и классификатор, ориентированный на канал](~/media/DLvsQCC.png)

<span data-ttu-id="1c675-125">Простое проектирование тактовой классификации можно сравнить с традиционным решением на машине поддержки (SVM).</span><span class="sxs-lookup"><span data-stu-id="1c675-125">A simple quantum classifier design can be compared to a traditional support vector machine (SVM) solution.</span></span> <span data-ttu-id="1c675-126">Вывод образца данных $x $ в случае SVM выполняется с помощью оптимальной формы ядра $ \сум \ alpha_j k (x_j, x) $, где $k $ является определенной функцией ядра.</span><span class="sxs-lookup"><span data-stu-id="1c675-126">The inference for a data sample $x$ in case of SVM is done using an optimal kernel form $\sum \alpha_j  k(x_j,x)$ where $k$ is a certain kernel function.</span></span>

<span data-ttu-id="1c675-127">Напротив, классификатор такта использует прогнозирующий $p (y │ x, U (\сета)) = 〈 U (\сета) x | M | U (\сета) x 〉 $, что похоже на сходство, но технически совершенно другое.</span><span class="sxs-lookup"><span data-stu-id="1c675-127">By contrast, a quantum classifier uses the predictor $p(y│x,U(\theta))=〈U(\theta)x|M|U(\theta)x〉$, which is similar in spirit but technically quite different.</span></span> <span data-ttu-id="1c675-128">Таким образом, при использовании простой кодировки амплитуды $p (y │ x, U (\сета)) $ является квадратичной формой в амплитудах $x $, но коэффициенты этой формы больше не изучены независимо друг от друга. Вместо этого они объединяются из элементов матрицы канала $U (\сета) $, которые, как правило, значительно меньше изученных параметров $ \сета $, чем размерность вектора $x $.</span><span class="sxs-lookup"><span data-stu-id="1c675-128">Thus, when a straightforward amplitude encoding is used,  $p(y│x,U(\theta))$ is a quadratic form in the amplitudes of $x$, but the coefficients of this form are no longer learned independently; they are instead aggregated from the matrix elements of the circuit $U(\theta)$, which typically has significantly fewer learnable parameters $\theta$ than the dimension of the vector $x$.</span></span> <span data-ttu-id="1c675-129">Степень полинома $p (y │ x, U (\сета)) $ в исходных функциях может быть увеличена до $2 ^ l $ с использованием тактовой кодировки продукта для $l $ копий $x $.</span><span class="sxs-lookup"><span data-stu-id="1c675-129">The polynomial degree of $p(y│x,U(\theta))$ in the original features can be increased to $2^l$ by using a quantum product encoding on $l$ copies of $x$.</span></span>

<span data-ttu-id="1c675-130">В нашей архитектуре рассматриваются относительно неполные каналы, которые, следовательно, должны быть *быстро ентанглинг* для захвата всех корреляций между функциями данных во всех диапазонах.</span><span class="sxs-lookup"><span data-stu-id="1c675-130">Our architecture explores relatively shallow circuits, which therefore must be *rapidly entangling* in order to capture all the correlations between the data features at all ranges.</span></span> <span data-ttu-id="1c675-131">Пример наиболее полезного компонента ентанглинг цепи показан на рисунке ниже.</span><span class="sxs-lookup"><span data-stu-id="1c675-131">An example of the most useful rapidly entangling circuit component is shown on figure below.</span></span> <span data-ttu-id="1c675-132">Несмотря на то, что канал с этой геометрической схемой состоит только из $3 n + 1 $ Gates, формируемая им матрица единого веса обеспечивает значительный обмен данными между компонентами $2 ^ n $.</span><span class="sxs-lookup"><span data-stu-id="1c675-132">Even though a circuit with this geometry consists of only $3 n+1$ gates, the unitary weight matrix that it computes ensures significant cross-talk between $2^n$ features.</span></span>

![Быстро ентанглинг тактовую цепь на 5 Кубитс (с двумя циклическими слоями).](~/media/5-qubit-qccc.png)

<span data-ttu-id="1c675-134">Цепь в приведенном выше примере состоит из 6 однокубитных шлюзов $ (G_1, \лдотс, G_5; G_ {16} ) $ и 10 2-Кубитс Gates $ (G_6, \лдотс, G_ {15} ) $.</span><span class="sxs-lookup"><span data-stu-id="1c675-134">The circuit in the above example consists of 6 single-qubit gates $(G_1,\ldots,G_5; G_{16})$ and 10 two-qubits gates $(G_6,\ldots,G_{15})$.</span></span> <span data-ttu-id="1c675-135">Предполагая, что каждый из шлюзов определен с одним из этих параметров, у нас есть 16 подученных параметров, а измерение 5-кубит Гильберта пространство — 32.</span><span class="sxs-lookup"><span data-stu-id="1c675-135">Assuming that each of the gates is defined with one learnable parameter we have 16 learnable parameters, while the dimension of the 5-qubit Hilbert space is 32.</span></span> <span data-ttu-id="1c675-136">Такая геометрия канала может быть легко обобщена любому $n $-кубит регистру, когда $n $ является нечетным, что дает цепи с $3 n + 1 $ параметрами для $2 ^ n $-многомерного пространства.</span><span class="sxs-lookup"><span data-stu-id="1c675-136">Such circuit geometry can be easily generalized to any $n$-qubit register, when $n$ is odd, yielding circuits with $3 n+1$ parameters for $2^n$-dimensional feature space.</span></span>

## <a name="classifier-training-as-a-supervised-learning-task"></a><span data-ttu-id="1c675-137">Обучение классификатора как контролируемая задача обучения</span><span class="sxs-lookup"><span data-stu-id="1c675-137">Classifier training as a supervised learning task</span></span>

<span data-ttu-id="1c675-138">Обучение модели-классификатора включает в себя поиск оптимальных значений его операционных параметров, что позволяет максимально увеличить среднюю вероятность получения правильных меток обучения по обучающим образцам.</span><span class="sxs-lookup"><span data-stu-id="1c675-138">Training of a classifier model involves finding optimal values of its operational parameters, such that they maximize the average likelihood of inferring the correct training labels across the training samples.</span></span>
<span data-ttu-id="1c675-139">Здесь мы будем беспокоиться только о двух уровнях классификации, т. е. в случае $d = $2 и только два класса с метками $y _1, y_2 $.</span><span class="sxs-lookup"><span data-stu-id="1c675-139">Here, we concern ourselves with two level classification only, i.e. the case of $d=2$ and only two classes with the labels $y_1,y_2$.</span></span>

> [!NOTE]
> <span data-ttu-id="1c675-140">Способ обобщения наших методов с произвольным числом классов заключается в замене Кубитс на кудитс, т. е. единицами такта с $d $ базисными состояниями и двусторонним измерением с $d $-Way.</span><span class="sxs-lookup"><span data-stu-id="1c675-140">A principled way of generalizing our methods to arbitrary number of classes is to replace qubits with qudits, i.e. quantum units with $d$ basis states, and the two-way measurement with $d$-way measurement.</span></span>

### <a name="likelihood-as-the-training-goal"></a><span data-ttu-id="1c675-141">Правдоподобие цели обучения</span><span class="sxs-lookup"><span data-stu-id="1c675-141">Likelihood as the training goal</span></span>

<span data-ttu-id="1c675-142">Учитывая проученную цепь тактовой $U (\сета) $, где $ \сета $ является вектором параметров и обозначая окончательную меру на $M $, средняя вероятность правильного вывода метки — $ $ \бегин{алигн} \Маскал{л} (\сета) = \фрак {1} {| \маскал{д} |} \лефт (\ sum_ {(x, y_1) \Ин\маскал{д}} P (M = y_1 | U (\сета) x) + \ sum_ {(x, y_2) \Ин\маскал{д}} P (M = y_2 | U (\сета) x) \ригхт) \енд{алигн} $ $ WHERE $P (M = y | z) $ является вероятностью измерения $y $ в состоянии такта $z $.</span><span class="sxs-lookup"><span data-stu-id="1c675-142">Given a learnable quantum circuit $U(\theta)$, where $\theta$ is a vector of parameters, and denoting the final measurement by $M$, the average likelihood of the correct label inference is $$ \begin{align} \mathcal{L}(\theta)=\frac{1}{|\mathcal{D}|} \left( \sum_{(x,y_1)\in\mathcal{D}} P(M=y_1|U(\theta) x) + \sum_{(x,y_2)\in\mathcal{D}} P(M=y_2|U(\theta) x)\right) \end{align} $$ where $P(M=y|z)$ is the probability of measuring $y$ in quantum state $z$.</span></span>
<span data-ttu-id="1c675-143">Здесь достаточно понять, что функция правдоподобия $ \Маскал{л} (\сета) $ является гладким в $ \сета $ и ее производная в любом $ \ theta_j $ может быть вычислена по сути тем же протоколом такта, который используется для вычисления самой функции правдоподобия.</span><span class="sxs-lookup"><span data-stu-id="1c675-143">Here, it suffices to understand that the likelihood function $\mathcal{L}(\theta)$ is smooth in $\theta$ and its derivative in any $\theta_j$ can be computed by essentially the same quantum protocol as used for computing the likelihood function itself.</span></span> <span data-ttu-id="1c675-144">Это позволяет оптимизировать спуск шкалы $ \Маскал{л} (\сета) $ по градиенту.</span><span class="sxs-lookup"><span data-stu-id="1c675-144">This allows for optimizing the $\mathcal{L}(\theta)$ by gradient descent.</span></span>

### <a name="classifier-bias-and-training-score"></a><span data-ttu-id="1c675-145">Смещение классификатора и оценка курса обучения</span><span class="sxs-lookup"><span data-stu-id="1c675-145">Classifier bias and training score</span></span>

<span data-ttu-id="1c675-146">Учитывая некоторые промежуточные (или окончательные) значения параметров в $ \сета $, нам нужно определить одно вещественное значение $b $ знать как *классификатор смещения* для выполнения вывода.</span><span class="sxs-lookup"><span data-stu-id="1c675-146">Given some intermediate (or final) values of the parameters in $\theta$, we need to identify a single real value $b$ know as *classifier bias* to do the inference.</span></span> <span data-ttu-id="1c675-147">Правило вывода метки работает следующим образом:</span><span class="sxs-lookup"><span data-stu-id="1c675-147">The label inference rule works as follows:</span></span> 
- <span data-ttu-id="1c675-148">Пример $x $ назначается меткой $y _2 $ if и только в том случае, если $P (M = y_2 | U (\сета) x) + b > $0,5 (RULE1) (в противном случае назначается метка $y _1 $)</span><span class="sxs-lookup"><span data-stu-id="1c675-148">A sample $x$ is assigned label $y_2$ if and only if $P(M=y_2|U(\theta) x) + b > 0.5$  (RULE1) (otherwise it is assigned label $y_1$)</span></span>

<span data-ttu-id="1c675-149">Явно $b $ должен быть в пределах $ (-0,5, + 0,5) $, чтобы быть осмысленным.</span><span class="sxs-lookup"><span data-stu-id="1c675-149">Clearly $b$ must be in the interval $(-0.5,+0.5)$ to be meaningful.</span></span>

<span data-ttu-id="1c675-150">Обучающий вариант $ (x, y) \ин \Маскал{д} $ считается неправильной *классификацией* с учетом смещения $b $ если метка, выводимая для $x $ в соответствии с RULE1, на самом деле отличается от $y $.</span><span class="sxs-lookup"><span data-stu-id="1c675-150">A training case $(x,y) \in \mathcal{D}$ is considered a *misclassification* given the bias $b$ if the label inferred for $x$ as per RULE1 is actually different from $y$.</span></span> <span data-ttu-id="1c675-151">Общее число неправильной классификации — это *показатель обучения* классификатора, заданный в $b $.</span><span class="sxs-lookup"><span data-stu-id="1c675-151">The overall number of misclassifications is the *training score* of the classifier given the bias $b$.</span></span> <span data-ttu-id="1c675-152">*Оптимальный* уровень смещения классификатора $b $ свертывает оценку обучения.</span><span class="sxs-lookup"><span data-stu-id="1c675-152">The *optimal* classifier bias $b$ minimizes the training score.</span></span> <span data-ttu-id="1c675-153">Это легко увидеть, учитывая предварительно вычисленные оценки вероятности $ \{ P (M = y_2 | U (\сета) x) | (x, \*) \Ин\маскал{д} \} $. оптимальное смещение классификатора можно найти по двоичному поиску в интервале $ (-0,5, + 0,5) $, установив максимум $ \ Log_2 (| \маскал{д} |) $ шаги.</span><span class="sxs-lookup"><span data-stu-id="1c675-153">It is easy to see that, given the precomputed probability estimates $\{ P(M=y_2|U(\theta) x) | (x,\*)\in\mathcal{D} \}$, the optimal classifier bias can be found by binary search in interval $(-0.5,+0.5)$ by making at most $\log_2(|\mathcal{D}|)$ steps.</span></span>

### <a name="reference"></a><span data-ttu-id="1c675-154">Справочник</span><span class="sxs-lookup"><span data-stu-id="1c675-154">Reference</span></span>

<span data-ttu-id="1c675-155">Эта информация должна быть достаточной для начала воспроизведения кода.</span><span class="sxs-lookup"><span data-stu-id="1c675-155">This information should be enough to start playing with the code.</span></span> <span data-ttu-id="1c675-156">Однако если вы хотите узнать больше об этой модели, прочитайте первоначальное предложение: [ *"генераторы тактов на основе цепи", Мария Счулд, Алекс Бочаров, Криста Своре и (Nathan виебе*](https://arxiv.org/abs/1804.00633)</span><span class="sxs-lookup"><span data-stu-id="1c675-156">However, if you want to learn more about this model, please read the original proposal: [*'Circuit-centric quantum classifiers', Maria Schuld, Alex Bocharov, Krysta Svore and Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span></span>

<span data-ttu-id="1c675-157">В дополнение к образцу кода вы увидите на следующих шагах, вы также можете начать изучение классификации тактов в [этом учебнике](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification) .</span><span class="sxs-lookup"><span data-stu-id="1c675-157">In addition to the code sample you will see in the next steps, you can also start exploring quantum classification in [this tutorial](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification)</span></span> 
